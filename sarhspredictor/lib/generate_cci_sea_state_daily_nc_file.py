# coding: utf-8
"""
January 2021
inspiration: hs_total_sar_v1_product_generation.py
A Grouazel
tested/validated in env /home1/datawork/agrouaze/conda_envs2/envs/cwave/bin/python
example usage:
python /home1/datahome/agrouaze/git/sar_hs_nn/sarhspredictor/lib/generate_cci_sea_state_daily_nc_file.py --outputdir /tmp/ --startdate 20200101 --stopdate 20200101 --sat S1B --wv wv2 --redo --cwave-version v3 --dev --verbose
"""



import logging
import sys
import xarray
import os
datacdir = os.path.abspath(os.path.join(os.path.dirname(__file__),'../data_collect'))
sys.path.append(datacdir)
import time
import glob
import netCDF4
import traceback
import os
import datetime
import collections
import numpy as np
import pandas as pd
import subprocess
import pdb
from dateutil import rrule
from shared_information import PROJECT_DIR_DATARMOR,sats_acro,DIR_HS_EMP_CWAVE_CCI,VERSION_CWAVE_CCI
from produce_list_file_S1 import writeTheFileList
from sarhspredictor.lib.predict_with_quach2020_on_OCN_using_keras import main_level_1
from sarhspredictor.lib.load_quach_2020_keras_model import load_quach2020_model_v2
sys.path.append('/home1/datahome/agrouaze/sources/test_openstreetmap_landmask/')
import swiml2sproc_utils_ancillary_landmask
#from cerbere.datamodel.trajectory import Trajectory
#from cerbere.datamodel.field import Field
#from cerbere.datamodel.variable import Variable
#from cerbere.mapper.ncfile import NCFile
#from cerbere.mapper.ncfile import WRITE_NEW
#from exploit_prun_hs_total_sar_txt_concat import concatenate_txt_hs
#from compute_Hs_total_SAR import compute_hs_total_SAR_v1
#from compute_hs_total_SAR_v2 import format_input_CWAVE_vector_from_OCN,compute_hs_total_SAR_v2,compute_hs_total_SAR_v2_1

# import landmask
land_polygon_path = '/home/datawork-cersat-exp/ipf/static/landmask/land_polygons'
land_raster_path = '/home/datawork-cersat-exp/ipf/static/landmask/land_raster.nc'

INPUT_TXT_DIR = '/home1/scratch/agrouaze/sentinel1/L2/WV/hs_total_SAR/v1/'
INPUT_TXT_DIR = '/home1/datahome/agrouaze/sentinel1/L2/WV/hs_total_SAR/v1/'
INPUT_TXT_DIR = '/home1/datawork/agrouaze/sentinel1/L2/WV/hs_total_SAR/v1/'
OUTDIR = '/home/cercache/users/agrouaze/temporaire/sentinel1/hs_total_SAR/hs_total_sar_v1_from_L2/'  # first directory for the version with some Hs total SAR bugged due to the mkl lib env issue
OUTDIR = '/home/datawork-cersat-public/project/cci-seastate/sandbox/data/sar/'  # path given by JFP in december2017
OUTDIR = '/home/datawork-cersat-public/project/cci-seastate/sandbox/data/sar/v1.0/'  # contained Hs total only separated by satellite
OUTDIR = '/home/datawork-cersat-public/project/cci-seastate/sandbox/data/sar/v1.1/'  # .nc separated by incidence angle and satellite
OUTDIR = DIR_HS_EMP_CWAVE_CCI
OUTDIR = '/home1/scratch/agrouaze/'
version_hs_computation = 'v1'  # orignal version reading the txt generated by PRUN
version_hs_computation = 'v1.1'  # new version that compute directly from netCDF with a corrected mkl lib in environement but still using the logpolar->cartesian conversion (January 2019)
version_hs_computation = VERSION_CWAVE_CCI
version_hs_computation = 'v3' # Quach 2020
units_dates = 'seconds since 2014-04-06 00:00:00'
# key: values (longname ,type,dimensions,units,descr/longname,vmin,vmax)
variables_infos = {  # ('time','str3')
    #"big_sat_acro" : ("satellite_name",'S3',('time',),'no units','first 3 characters of satellite name',None,None),
    #'big_kcorrup' : ("flag_k_vector_corrupted",'f4',('time',),'no units',
    #                 'flag to indicate if the k vector of original ESA product is corrupted (True) or not (False)',None,
    #                 None),
    'swh' : ("sea_surface_wave_significant_height",'f8',('time',),'m','C band significant wave height',0,30),
    'swh_uncertainty' : (
                        'swh_uncertainty','f8',('time',),'m','standard deviation associated to hs :  level of confidence of the NN model ',0,6),
    'swh_quality':("swh_quality","byte",('time'),"","quality of C band significant wave height measurement","",""),
    'swh_rejection_flags':('swh_rejection_flags','byte',('time'),'','consolidated instrument and ice flags',"",""),
    'incidence_angle' : ("incidence_angle",'f8',('time',),'degree','incidence angle of the WV acquisition',22,38),
    'oswLandFlag':('land_flag','byte',('time'),'','land flag annotated in ESA OCN WV products',0,1),
    'distance_to_coast':('distance_to_coast','f8',('time'),'km','distance to coast for WV image center using hybrid method raster/polygons openstreemap',0,4000),
    'platformName':('platform_name','S3',('time'),'','name of the satellite','',''),
    'lon':('longitude','f8',('time'),'degrees_east','longitude',-180,180),
    'lat':('latitude','f8',('time'),'degrees_north','latitude',-90,90),
    'nrcs' : ("sigma0",'f8',('time',),'dB','sigma0 (Normalized Radar Cross Section)',-30,10),
    'nv' : ("nv",'f8',('time',),'dB','Normalized variance of sigma0',1,3),
    'wind_speed' : ("wind_speed",'f8',('time',),'m.s-1','wind speed coming from ESA OCN WV product (CMOD-based wind inversion without Bayesian scheme)',0,50),
    'heading' : ("satellite_heading",'f8',('time',),'degrees',
                     'satellite heading relative to geographic North in clockwise convention',0,360),
    #'time':('time','f8',('time'),units_dates,'')
}



def read_infos_from_WV_ifremer_archive_v2 ( datedt,sato,wv,dev=False ) :
    """
    read OCN L2 WV data and compute on the fly the Hs predicted by NN model
    :args:
        datedt (datetime): day to analyze
        sato (str): S1A
        wv (str): wv1 or wv2
    """
    cpt = collections.defaultdict(int)
    sto = (datedt).strftime('%Y%m%d')
    measu_list = []
    for ss in [sato] :
        datadir = os.path.join(PROJECT_DIR_DATARMOR,'data','esa',sats_acro[ss],'L2')
        ogpath,measu_listtmp = writeTheFileList('WV','OCN_',datadir,datedt.strftime('%Y%m%d'),enddate=sto,satellite=ss,
                                                level='L2',onlyonsea=False,write_to_file=False)
        # filter on incidence angle
        measu_listtmp2 = [ffh for ffh in measu_listtmp if wv in ffh]

        measu_list += sorted(measu_listtmp2)
    if dev:
        logging.warning('dev mode reduction of input listing to first 2 ocn')
        measu_list = measu_list[0:2]
    logging.info('Nb ocn files to read: %s',len(measu_list))
    s1_ocn_wv_ds = main_level_1(measu_list[: :-1],model)
    #TODO add distance to coast and land flag with open street map, see swiml2sproc_utils_ancillary_landmask.py function get_landmask()
    return s1_ocn_wv_ds


def write_netcdf_file_xarray ( s1_ocn_wv_ds,filout,wv,cwave_verison,redo=True ,remove_training_vars=True) :
    """
    format output daily file (xarray replace cerbere)
    :args:
        s1_ocn_wv_ds : Xarray.Dataset
        wv (str): wv1 or wv2
        cwave_verison (str):
        redo: (bool)
    """
    logging.debug('add swh_quality')
    qcs = np.zeros(len(s1_ocn_wv_ds['oswLon']))
    one_std = np.std(s1_ocn_wv_ds['swh_uncertainty'].values)
    qcs[s1_ocn_wv_ds['swh_uncertainty']<one_std] = 3
    qcs[(s1_ocn_wv_ds['swh_uncertainty'] >= one_std) & (s1_ocn_wv_ds['swh_uncertainty'] < 2*one_std)] = 2
    qcs[(s1_ocn_wv_ds['swh_uncertainty'] >= 2*one_std) ] = 1
    s1_ocn_wv_ds['swh_quality'] = xarray.DataArray(qcs,dims=s1_ocn_wv_ds['swh_uncertainty'].dims,coords=s1_ocn_wv_ds['swh_uncertainty'].coords)
    s1_ocn_wv_ds['swh_rejection_flags']= xarray.DataArray(np.zeros(len(s1_ocn_wv_ds['oswLon'])),
                                dims=s1_ocn_wv_ds['swh_uncertainty'].dims,coords=s1_ocn_wv_ds['swh_uncertainty'].coords)
    #add distance to coast
    landmask,distance_to_coast = swiml2sproc_utils_ancillary_landmask.get_landmask(s1_ocn_wv_ds['oswLon'].values,
                                    s1_ocn_wv_ds['oswLat'].values,land_polygon_path,land_raster_path,debug_figures=False)
    s1_ocn_wv_ds['distance_to_coast']= xarray.DataArray(distance_to_coast,
                                dims=s1_ocn_wv_ds['swh_uncertainty'].dims,coords=s1_ocn_wv_ds['swh_uncertainty'].coords)
    logging.debug('rename')
    s1_ocn_wv_ds  = s1_ocn_wv_ds.rename({'oswLon':'lon','oswLat':'lat','oswWindSpeed':'wind_speed'})
    if remove_training_vars:
        s1_ocn_wv_ds = s1_ocn_wv_ds.drop(['S','cwave','incidence','latlonSARcossin','dxdt','todSAR','oswIncidenceAngle'])
        s1_ocn_wv_ds = s1_ocn_wv_ds.drop(['oswQualityCrossSpectraRe','satellite'])
        s1_ocn_wv_ds = s1_ocn_wv_ds.drop(['oswQualityCrossSpectraIm','Sdim','cwavedim','dxdtdim','latlondim','incdim','oswAngularBinSize','oswWavenumberBinSize'])
    if len(s1_ocn_wv_ds['swh_uncertainty'])>0:

        #add var attributes
        for kk in s1_ocn_wv_ds.keys():
            logging.debug('att start with : %s',kk)
            if s1_ocn_wv_ds[kk].values.dtype=='float32' or s1_ocn_wv_ds[kk].values.dtype=='float64' or s1_ocn_wv_ds[kk].values.dtype=='int':
                # mask nan elements -> add a fillvalue
                masked_vals = np.ma.masked_where(np.isnan(s1_ocn_wv_ds[kk].values),s1_ocn_wv_ds[kk].values,copy=True)
            else:
                logging.info('variable %s doesnt contains numeric values : %s',kk,s1_ocn_wv_ds[kk].values.dtype)
                masked_vals = s1_ocn_wv_ds[kk].values
            if isinstance(masked_vals,np.ndarray):
                masked_vals = np.ma.array(masked_vals)
                logging.info('je triche je cast du masked : %s',type(masked_vals))
            s1_ocn_wv_ds[kk] = xarray.DataArray(masked_vals,dims=s1_ocn_wv_ds[kk].dims,coords=s1_ocn_wv_ds.coords)
            logging.debug('%s %s ',kk,type(s1_ocn_wv_ds[kk].values))
            if kk in variables_infos:

                s1_ocn_wv_ds[kk].attrs['unit'] = variables_infos[kk][3]
                s1_ocn_wv_ds[kk].attrs['description'] =variables_infos[kk][4]
                s1_ocn_wv_ds[kk].attrs['standard_name'] = variables_infos[kk][0]
                if kk in ['platformName']:
                    pass
                else:
                    s1_ocn_wv_ds[kk].attrs['vmin'] =variables_infos[kk][5]
                    s1_ocn_wv_ds[kk].attrs['vmax'] =variables_infos[kk][6]
                s1_ocn_wv_ds[kk].attrs['coordinates'] = "lat lon"
                s1_ocn_wv_ds[kk].attrs['authority'] = "CF 1.7"
                s1_ocn_wv_ds[kk].attrs['least_significant_digit'] = '3L'
                if 'fill_value' in dir(s1_ocn_wv_ds[kk].values): #je ne comprend pas pourquoi le type des values nest pas updated
                    s1_ocn_wv_ds[kk].attrs['_FillValue'] = s1_ocn_wv_ds[kk].values.fill_value
                if kk in ['swh']:
                    s1_ocn_wv_ds[kk].attrs['coverage_content_type'] = "physicalMeasurement"
                    s1_ocn_wv_ds[kk].attrs['ancillary_variables'] = "swh_quality swh_rejection_flags"
                    s1_ocn_wv_ds[kk].attrs['band'] = "C"
                elif kk in ['wind_speed']:
                    s1_ocn_wv_ds[kk].attrs['coverage_content_type'] = "physicalMeasurement"
                    s1_ocn_wv_ds[kk].attrs['band'] = "C"
                elif kk in 'swh_quality':
                    s1_ocn_wv_ds[kk].attrs['least_significant_digit'] = '0L'
                    s1_ocn_wv_ds[kk].attrs['flag_values'] = "0L, 1L, 2L, 3L"
                    s1_ocn_wv_ds[kk].attrs['flag_meanings'] = "undefined bad acceptable good"
                    s1_ocn_wv_ds[kk].attrs['coverage_content_type'] = "qualityInformation"
                    s1_ocn_wv_ds[kk].attrs['band'] = "C"
                elif kk in 'swh_rejection_flags':
                    s1_ocn_wv_ds[kk].attrs['least_significant_digit'] = '0L'
                    s1_ocn_wv_ds[kk].attrs['flag_masks'] = "1L, 2L, 4L, 8L, 16L, 32L, 64L, 128L"
                    s1_ocn_wv_ds[kk].attrs['flag_meanings'] = "nb_of_valid_swh_too_low swh_validity not_water sea_ice sigma0_validity waveform_validity swh_rms_outlier swh_outlier"
                    s1_ocn_wv_ds[kk].attrs['coverage_content_type'] = "qualityInformation"
                    s1_ocn_wv_ds[kk].attrs['band'] = "C"



                logging.debug('attrb for %s added: %s',kk,s1_ocn_wv_ds[kk].attrs)
            elif kk in ['time']:
                s1_ocn_wv_ds[kk].attrs['longname'] = "start time of the WV acquisition (lasts less than 3 seconds for one image)"
            else:
                logging.error('no att for %s',kk)
        globatt = {
            'institution' : 'University of Hawaii , Laboratory of Physical and Spatial Oceanography  Institut Français pour la Recherche et l Exploitation de la MER, European Space Agency',
            'institution_abbreviation' : 'UH , LOPS-IFREMER, ESA',
            'publisher_name' : "ifremer/LOPS",
            'publisher_url' : "https://www.umr-lops.fr/",
            'publisher_email' : "lops-siam@listes.ifremer.fr",
            'PIs' : 'Justin Stopa, Alexis Mouche',
            #'reference paper' : 'Stopa, Mouche JGR oceans 2017 https://doi.org/10.1002/2016JC012364',
            'reference paper': 'Quach et al 2020 https://authors.library.caltech.edu/104562/1/09143500.pdf',
            'incidence_angle' : wv,
            'version of NN model' : cwave_verison,
            'time_coverage_start' : str(s1_ocn_wv_ds['time'].min().values), #"2017-01-01T00:28:08Z" ;             #new att like cerbere
            'time_coverage_end' : str(s1_ocn_wv_ds['time'].max().values),
            'Conventions' : "CF-1.7, ACDD-1.3, ISO 8601" ,
            'title' : "ESA CCI Sea State L2 ESA OCN from Sentinel-1",
            'id' : "ESACCI-SEASTATE-L2P-SWH-Sentinel1" ,
            #'institution = "Institut Francais de Recherche pour l\'Exploitation de la mer / CERSAT, European Space Agency" ;
            'source' : "CCI Sea State Sentinel-1 statistical Hs Processor",
            'history' : "%s - Creation"%datetime.datetime.today().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'references' : "CCI Sea State Product Specification Document (PSD), v1.1",
            'product_version' : "1.0",
            'summary' : "This dataset contains significant wave height measurements from Sentinel-1 SAR" ,
            'keywords' : ("Oceans > Ocean Waves > Significant Wave Height", "Oceans > Ocean Waves > Sea State"),
            'keywords_vocabulary' : "NASA Global Change Master Directory (GCMD) Science Keywords",
            'naming_authority' : "fr.ifremer.cersat" ,
            'cdm_data_type' : "trajectory",
            'featureType' : "trajectory" ,
            'comment' : "These data were produced at ESACCI as part of the ESA SST CCI project.",
            'creator_name' : "ifremer/LOPS" ,
            'creator_url' : "https://www.umr-lops.fr/" ,
            'creator_email' : "lops-siam@listes.ifremer.fr" ,
            'creator_institution' : "Ifremer / LOPS" ,
            'project' : "Climate Change Initiative - European Space Agency" ,
            'geospatial_lat_min' : -80. ,
            'geospatial_lat_max' : 80. ,
            'geospatial_lat_units' : "degree_north" ,
            'geospatial_lon_min' : -180. ,
            'geospatial_lon_max' : 180. ,
            'geospatial_lon_units' : "degree_east" ,
            'standard_name_vocabulary' : "NetCDF Climate and Forecast (CF) Metadata Convention version 1.7" ,
            'license' : "ESA CCI Data Policy: free and open access" ,
            'platform' : "Sentinel-1" ,
            'platform_type' : "low earth orbit satellite" ,
            'platform_vocabulary' : "CCI" ,
            'instrument' : "C-band SAR" ,
            'instrument_type' : "SAR (Synthetic Aperture Radar)" ,
            'instrument_vocabulary' : "CCI" ,
            'spatial_resolution' : "20x20 km" ,
            'netcdf_version_id' : "%s"%netCDF4.__version__,
            'acknowledgement' : "Please acknowledge the use of these data with the following statement: these data were obtained from the ESA CCI Sea State project" ,
            'format_version' : "Data Standards v2.1" ,
            'processing_level' : "L2P" ,
            'scientific_support_contact' : "stopa@hawaii.edu" ,
            'technical_support_contact' : "cersat@ifremer.fr" ,
            'key_variables' : "swh" ,
            'date_created' : datetime.datetime.today().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'date_modified' : datetime.datetime.today().strftime('%Y-%m-%dT%H:%M:%SZ'),
            'band' : "C" ,
            'source_version' : "" ,
            'input' : "Level-2 ESA WV OCN products" ,
            'Metadata_Conventions' : "Climate and Forecast (CF) 1.7, Attribute Convention for Data Discovery (ACDD) 1.3" ,
            'geospatial_vertical_units' : "meters above mean sea level" ,
            'geospatial_vertical_positive' : "up"

        }
        for kki in globatt:
            s1_ocn_wv_ds.attrs[kki] = globatt[kki]
        s1_ocn_wv_ds.to_netcdf(filout)
        logging.info('done! output : %s',filout)
        status = 'written'
    else :
        logging.info('there is no hs total SAR for this day and this satellite %s',filout)
        status = 'nodata'
    return status


def process_one_day_v2 ( dd,args ) :
    """
    wrapper of the different methods
    version 2: skip txt files and compute the Hs total directly from netCDF ESA OCN
    """
    final_df = None
    if args.outputdir is None :
        outputdir = os.path.join(OUTDIR,args.cwave_version,args.sat + '_' + args.wv)
    else :
        outputdir = os.path.join(args.outputdir,args.cwave_version,args.sat + '_' + args.wv)
    filout = os.path.join(outputdir,dd.strftime('%Y'),dd.strftime('%j'),args.sat + '_' + args.wv + '_' + dd.strftime(
        '%Y%m%d') + '_level2_LOPS_SWH_SAR_%s.nc' % args.cwave_version)
    logging.info('version2, final path: %s',filout)
    dira = os.path.dirname(filout)
    if os.path.exists(dira) == False :
        os.makedirs(dira,0o0755)
        logging.info('make dir %s',dira)
    if os.path.exists(filout) and args.redo == True :
        os.remove(filout)
    if os.path.exists(filout) and args.redo == False :
        status = 'already_in'
    else :
        logging.info('outputdir = %s',outputdir)
        final_ds = read_infos_from_WV_ifremer_archive_v2(dd,args.sat,args.wv,dev=args.dev)
        logging.debug('%s',final_ds.keys())
        logging.debug('%s',final_ds.count())
        logging.info('write the final netCDF')
        status = write_netcdf_file_xarray(final_ds,filout,cwave_verison=args.cwave_version,redo=args.redo,wv=args.wv)

    return status,final_df


if __name__ == '__main__' :
    tinit = time.time()
    root = logging.getLogger()
    if root.handlers :
        for handler in root.handlers :
            root.removeHandler(handler)
    import argparse

    parser = argparse.ArgumentParser(description='hs_sar_product')
    parser.add_argument('--verbose',action='store_true',default=False)
    parser.add_argument('--outputdir',default=None,help='folder where the data will be written [optional]',
                        required=False)
    parser.add_argument('--startdate',required=True,help='YYYYMMDD',type=str)
    parser.add_argument('--stopdate',required=True,help='YYYYMMDD',type=str)
    parser.add_argument('--sat',required=True,help='S1A or S1B...',type=str)
    parser.add_argument('--wv',required=True,help='wv1 or wv2...',type=str)
    parser.add_argument('--redo',action='store_true',default=False,help='redo existing files nc')
    parser.add_argument('--cwave-version',required=True,help='example  v1.2')
    parser.add_argument('--dev',action='store_true',default=False,help='dev/test mode only 2 wv measu treated in a day')
    args = parser.parse_args()
    fmt = '%(asctime)s %(levelname)s %(filename)s(%(lineno)d) %(message)s'
    if args.verbose :
        logging.basicConfig(level=logging.DEBUG,format=fmt,
                            datefmt='%d/%m/%Y %H:%M:%S')
    else :
        logging.basicConfig(level=logging.INFO,format=fmt,
                            datefmt='%d/%m/%Y %H:%M:%S')
    #     datedt = datetime.datetime(2017,1,25,)
    model = load_quach2020_model_v2() #heteroskedastik 2017 for format validation before final model release from Hawaii team
    sta = datetime.datetime.strptime(args.startdate,'%Y%m%d')
    sto = datetime.datetime.strptime(args.stopdate,'%Y%m%d')
    cptu = collections.defaultdict(int)

    for dd in rrule.rrule(rrule.DAILY,dtstart=sta,until=sto) :
        t0 = time.time()
        cptu['total_days'] += 1
        status,final_df = process_one_day_v2(dd,args)
        cptu[status] += 1
        elapsed = datetime.timedelta(seconds=(time.time() - t0))
        logging.info('time to write one file = %s',elapsed)
    logging.info('counter = %s',cptu)
    logging.info('script main finished in %1.1f seconds',time.time()-tinit)
